# Program AI 2: Application of Generative AI

## Program Overview

- **Total Lessons**: 24
- **Session Duration**: 1 hour per session
- **Meeting Frequency**: Weekly mentor check-ins via Zoom
- **Program Duration**: Approximately 6 months
- **Class Size**: 1 teacher per 8 students

## Program Structure

1. Part I: Foundations of Generative AI & Customization of LLM (Lessons 1-8)
2. Part II: Tools with AI - Creative Applications (Lessons 9-15)
3. Part III: Capstone - Deploying a Real AI Project (Lessons 16-24)

## Part I: Foundations of Generative AI & Customization of LLM (Lessons 1-8)

### Lesson 1: Introduction to Generative AI & Core Concepts

**Objective**: Introduce what AI is and the role of large-language models (LLMs).

**Content**:
- Definitions and basic vocabulary (e.g., Artificial Intelligence, LLM, Model, Training Data)
- Overview of the self-supervised learning process
- (Adapted from Foundations Lesson 1)

### Lesson 2: Data, Training, and Bias in AI

**Objective**: Understand how LLMs are trained using curated data and how bias emerges from these processes.

**Content**:
- The importance of data curation
- How bias in training data can affect outputs
- Activity: Analyze sample training data to identify potential biases
- (Combines Foundations Lessons 2 & 3)

### Lesson 3: Word Representations: Embeddings and Neural Networks

**Objective**: Explain how words are converted into numerical embeddings and introduce the basics of neural networks.

**Content**:
- Conversion of words into embeddings and their significance
- Overview of neural networks (weights, biases, layers) and their role in LLM functionality
- (Merges Foundations Lessons 4, 5, and a trimmed version of Lesson 6)

### Lesson 4: Advanced Model Mechanisms: Attention & Output Generation

**Objective**: Dive into how attention mechanisms refine embeddings and how models generate outputs.

**Content**:
- The role of attention in using context to update embeddings
- How probability distributions govern output generation and the phenomenon of hallucinations
- (Based on Foundations Lessons 8, 9, and 10)

### Lesson 5: Interacting with Language Models & Prompt Engineering

**Objective**: Provide hands-on experience interacting with an LLM and introduce basic prompt engineering.

**Content**:
- Using tools like AI Chat Lab to interact with an LLM
- Crafting system prompts and experimenting with simple prompt variations
- (Integrates Customizing Lessons 1-3)

### Lesson 6: Advanced Prompt Strategies & Retrieval Techniques

**Objective**: Enhance prompt engineering skills and introduce retrieval methods for enriching model responses.

**Content**:
- Advanced prompting techniques (e.g., few-shot, chain-of-thought)
- Integrating external data sources to enhance context
- (Draws on Customizing Lessons 4-8)

### Lesson 7: Evaluating Models: Model Cards & Fine-Tuning

**Objective**: Teach students how to document and evaluate model performance, and explore fine-tuning for specialized tasks.

**Content**:
- Creating and using Model Cards for performance documentation and ethical review
- Techniques for fine-tuning an LLM
- (Combines Customizing Lessons 9-10 and Lesson 14)

### Lesson 8: Capstone: Designing an Ethical Chatbot

**Objective**: Synthesize foundational and customization techniques by designing a personal, ethically-driven chatbot.

**Content**:
- Integrating learned customization techniques
- Incorporating issue statements and user feedback
- Discussion on societal and ethical impacts of chatbots
- (Synthesizes Customizing Lessons 11-13, 15, and a trimmed version of Lesson 16)

## Part II: Tools with AI - Creative Applications (Lessons 9-15)

### Lesson 9: Creative Image Generation and Overview of AI Tools

**Objective**: Introduce a range of creative AI tools with a focus on text-to-image generation using Midjourney.

**Content**:
- Brief overview of various creative tools:
  - Midjourney: Text-to-image generation (or alternatives like Crayon/Doubao chat)
  - Twine: Interactive narrative design
  - NotebookLM: Document synthesis
  - Music/Audio Generation: Tools for music and soundscape creation
  - Signtown: Interactive design exploration
- Detailed focus on how creative prompts influence image outputs in Midjourney

**Activity**:
- Group discussion to brainstorm creative applications of these tools
- Guided hands-on session with Midjourney to generate a gallery of artistic images, followed by peer critique

### Lesson 10: Interactive Storytelling and Narrative Design with Twine

**Objective**: Develop interactive, branching narratives that adapt to user choices.

**Tools**:
- Twine (optionally integrated with a GPT-based text generator)

**Content**:
- Fundamentals of narrative design, branching structures, and adaptive storytelling techniques

**Activity**:
- Workshop: Students draft a short interactive story with multiple narrative paths
- Share-out session to discuss narrative choices and the influence of AI-generated text

### Lesson 11: Document Synthesis with NotebookLM

**Objective**: Leverage AI to synthesize extensive textual data into organized documents (e.g., an auditor book).

**Tools**:
- NotebookLM

**Content**:
- Techniques for summarizing and structuring large volumes of text, applied to diverse topics such as science, business, or sports

**Activity**:
- Guided exercise with a worksheet to outline and generate document sections
- Discussion to evaluate the clarity and organization of the synthesized document

### Lesson 12: Extended NotebookLM Project - Podcast Audio Generation

**Objective**: Extend document synthesis by creating a podcast-style audio segment on a selected topic.

**Tools**:
- NotebookLM combined with text-to-speech tools

**Content**:
- Strategies for converting synthesized text into engaging audio content

**Activity**:
- Project work: Students produce a short podcast audio explaining their chosen topic
- Peer review session focusing on narrative coherence and presentation

### Lesson 13: Music and Audio Generation - Composition

**Objective**: Transform textual descriptions into musical compositions or soundscapes.

**Tools**:
- Chrome Music Lab - Song Maker, Soundraw.io, or similar tools

**Content**:
- How text prompts determine musical parameters like rhythm, melody, and tone

**Activity**:
- Guided demo where students generate short music clips from creative prompts
- Group discussion to compare and refine creative outputs

### Lesson 14: Music and Audio Generation - Voice Synthesis and Narration

**Objective**: Create custom audio narrations and experiment with AI-generated voices.

**Tools**:
- Eleven Labs or similar voice synthesis tools

**Content**:
- Techniques behind voice cloning and generating natural-sounding audio narrations

**Activity**:
- Hands-on session: Students produce short voice samples or narrations for a character or story
- Peer review focused on emotional impact, clarity, and overall quality

### Lesson 15: Interactive Design Exploration with Signtown

**Objective**: Explore generative design to create dynamic digital signatures or visual elements.

**Tools**:
- Signtown (via Project Shuwa)

**Content**:
- Fundamentals of generative design and visual manipulation

**Activity**:
- Design challenge: Students create a digital signature or a small visual project
- Critique session to discuss design choices and potential real-world applications

## Part III: Capstone - Deploying a Real AI Project (Lessons 16-24)

### Overall Capstone Goal

Students will integrate advanced LLM techniques, interactive interface design, and ethical considerations to build and deploy a fully functional AI application. The capstone project will demonstrate their ability to create a real-world, deployable solution.

### Lesson 16: Capstone Introduction & Project Planning

**Objective**:
- Introduce the capstone framework and help students brainstorm and plan their project (e.g., chatbot streaming, data-driven applications, diffusion-based image generation)

**Activity**:
- Group brainstorming, proposal writing, and project plan development outlining goals, tools, and anticipated challenges

### Lesson 17: Navigating Advanced LLM Models on Hugging Face

**Objective**:
- Deepen familiarity with the Hugging Face ecosystem, including selecting and understanding open-source models (e.g., Llama 3.1, DeepSeek R1)

**Activity**:
- Guided exploration of the Model Hub; students select a model for their project and justify their choice

### Lesson 18: Building Interactive Demos with Gradio

**Objective**:
- Teach students to wrap their chosen LLM with Gradio to create a user-friendly interactive demo

**Activity**:
- Code-along session to build a basic interface (e.g., "Hello World" or a simple Q&A app) that serves as the front end of their project

### Lesson 19: Integrating External Data and Advanced Prompt Engineering

**Objective**:
- Enhance project functionality by integrating external data sources and refining prompts for improved output quality

**Activity**:
- Hands-on workshop: Students incorporate retrieval components or fine-tune prompts to manage complex tasks, such as real-time data queries or multi-turn conversations

### Lesson 20: Deployment Strategies and Best Practices

**Objective**:
- Prepare students for real-world deployment by discussing version control, environment setup, and scalability (using platforms like Hugging Face Spaces or Together API)

**Activity**:
- Step-by-step walkthrough: Students deploy a prototype of their project to an online platform

### Lesson 21: Security, Monitoring, and Ethical Considerations

**Objective**:
- Address critical issues such as data privacy, security best practices, performance monitoring, and ethical challenges in deployed AI systems

**Activity**:
- Case study discussion and group brainstorming on securing and monitoring applications; students document ethical considerations

### Lesson 22: Iterative Improvement and User Feedback Integration

**Objective**:
- Teach iterative design techniques, including gathering user feedback and A/B testing, to refine the application

**Activity**:
- Simulated feedback session (or live testing) where students use feedback to make concrete improvements to their projects

### Lesson 23: Capstone Project Finalization

**Objective**:
- Focus on testing, debugging, optimizing, and finalizing the AI application for a polished, deployable project

**Activity**:
- In-class lab: Students address final technical challenges, optimize performance, and undergo peer review for last-minute feedback

### Lesson 24: Capstone Project Presentation and Reflection

**Objective**:
- Present the final project, receive critiques, and reflect on the learning journey

**Activity**:
- Final showcase: Students present their deployed applications (e.g., interactive chatbots, data-driven apps, diffusion-based image generators) followed by a reflective discussion on challenges, successes, and ethical implications

This comprehensive 24-lesson course outline for Program AI-2 seamlessly combines foundational generative AI principles, creative tool exploration, and advanced real-world deployment skills. It equips students with both theoretical knowledge and practical, hands-on experience, culminating in a capstone project that showcases their ability to build, deploy, and critically assess an interactive AI application.